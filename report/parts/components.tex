% Компоненты среды разработки -- 5
\section{Компоненты среды разработки}
    Компилятор языка состоит из пяти основных компонентов.
    К ним относятся: чтение входного потока, лексический, синтаксический и семантический анализаторы и генератор кода.
    \subsection{Чтение входного потока}
    На этом этапе происходит чтение текста программы из файла и предварительное его разделение на <<слова>>.

    <<Словом>> является:
    \begin{itemize}
        \item любая последовательность символов, заключённая в двойные кавычки;
        \item любой терминальный символ (символ переноса строки, пробел, табуляция, окончание файла);
        \item последовательность символов, образующая слово $scheme$, если она не входит в состав другого <<слова>>;
        \item последовательность символов, заключённых в круглые скобки, следующая за словом $scheme$ и отделённая от него одним или несколькими <<словами>>, являющимися терминальными символами;
        \item любая иная последовательность символов, не содержащая терминальных символов.
    \end{itemize}

    После этого этапа мы получаем список <<слов>>, который подаётся на вход лексическому анализатору.
    
    \subsection{Лексический анализ}
    На этом этапе осуществляется преобразование последовательности <<слов>> в последовательность токенов.
    Это происходит по следующей схеме.

    Сначала проверяется, входит ли данное <<слово>> в список ключевых слов.
    Если проверка оказывается успешной, то вычисляются координаты и создаётся токен с тэгом \verb$tag-kw$, значением которого будет являтся само <<слово>>.
    При этом, если ключевое слово является словом $scheme$, то ближайшее следующее за ним нетерминальное слово будет значением нового токена с тэгом \verb$tag-schm$.

    Затем осуществляется проверка является ли <<слово>> корректным числом.
    Если так, то высчитываются его координаты и создаётся токен с числовым тэгом.
    Значению этого токена присваивается вычисленное на этапе проверки число.

    После этого проверяется, является ли <<слово>> <<строкой>>, то есть последовательностью символов, заключённых в кавычки.
    Аналогично предыдущим пунктам вычисляются координаты и создаётся новый токен с тэгом \verb$tag-str$.

    В случае, если ни одна из этих проверок не увенчалась успехом, данное <<слово>> преобразуется в последовательность символов и дальнейшая проверка будет по-символьной.

    Если среди последовательности символов нам встретился символ $;$, дальнейшие символы этого <<слова>> и последующих игнорируются, пока не встретится символ переноса строки.

    Если среди последовательности символов встречается один из следующих: \verb!( ) [ ] { } . :!, то эта последовательность разбивается на три части:
    \begin{enumerate}
        \item сам символ;
        \item последовательность символов до него (возможно, пустая);
        \item последовательность символов после (возможно, пустая).
    \end{enumerate}
    Первая часть преобразуется в токен, с тэгом, соответствующем символу.
    Вторая и третья подвергаются анализу как отдельные <<слова>>.

    Для каждого элемента группы символов \verb,\ < ^ # !,, существует свой тэг.
    Но он останется у токена, только если этот символ был в <<слове>> единственным.

    Итоговый тэг для следующей группы символов: \verb!- + * t f / > | & =! определяется по тому является ли символ первым в слове или он следует за каким-то другим.
    Например, символ $-$ может получить тэг \verb$tag-mns$, если этот символ в слове первый.
    Если перед ним в <<слове>> стоит символ $<$ с тэгом \verb$tag-lwr$, то итоговый тэг изменится на \verb$tag-to$.
    Но если перед символом $-$ стоит какой-то другой символ или последовательность, то итоговый тэг будет -- \verb$tag-sym$, и вся эта последовательность станет токеном идентификатора.
    
    \subsection{Синтаксический анализ}
    
    \subsection{Семантический анализ}
    \subsection{Генерация кода}
